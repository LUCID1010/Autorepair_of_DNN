# Autorepair_of_DNN
This project uses LoRA fine-tuning to "repair" RoBERTa's robustness. By training on corrupted SNLI data, the model learns to ignore input errors while maintaining high accuracy on clean text.
